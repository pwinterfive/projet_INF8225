{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center>\n<h1> Projet INF8225 :\n<h2> Classification de sentiment : LSTM / BiLSTM / google algorithm : BERT\n<h4> Patrick Iversenc (2162564)\n<h4> Mirado Rabenasolo\n\n    ","metadata":{}},{"cell_type":"markdown","source":"<h2> Imports :","metadata":{}},{"cell_type":"code","source":"!pip install pyspellchecker\n!pip install spacy","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:10:43.279843Z","iopub.status.idle":"2022-04-30T21:10:43.280336Z","shell.execute_reply.started":"2022-04-30T21:10:43.280063Z","shell.execute_reply":"2022-04-30T21:10:43.280089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wordcloud","metadata":{"execution":{"iopub.status.busy":"2022-04-30T02:18:30.580676Z","iopub.execute_input":"2022-04-30T02:18:30.581028Z","iopub.status.idle":"2022-04-30T02:18:40.994335Z","shell.execute_reply.started":"2022-04-30T02:18:30.580979Z","shell.execute_reply":"2022-04-30T02:18:40.993321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport spacy\nimport os\nfor dirname, _, filenames in os.walk('/archives'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport nltk\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom nltk.stem.porter import *\nimport re\nfrom sklearn.pipeline import Pipeline","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-04-30T21:18:18.346155Z","iopub.execute_input":"2022-04-30T21:18:18.346692Z","iopub.status.idle":"2022-04-30T21:18:29.42785Z","shell.execute_reply.started":"2022-04-30T21:18:18.346653Z","shell.execute_reply":"2022-04-30T21:18:29.427083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sn\nfrom wordcloud import WordCloud\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:18:48.86389Z","iopub.execute_input":"2022-04-30T21:18:48.864165Z","iopub.status.idle":"2022-04-30T21:18:48.869424Z","shell.execute_reply.started":"2022-04-30T21:18:48.864134Z","shell.execute_reply":"2022-04-30T21:18:48.868048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> Data Import","metadata":{}},{"cell_type":"code","source":"!ls","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On a un problème d'encoding de la data, nous sommes obligé de la rencodé en latin\n# On enlève les lignes que nous ne voulons pas\n# On drop les lignes contenant des NaN\nfull_data = pd.read_csv('../input/data-groups/full_data_cleaned2.csv').dropna()\n\n# On renomme les colones avec nos termes pour être plus à l'aise\ncolumns_names = list(full_data)\nfull_data.rename(columns={columns_names[0]:\"label\",\n                        columns_names[1]:\"text\"}, inplace= True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T02:21:23.034784Z","iopub.execute_input":"2022-04-30T02:21:23.03558Z","iopub.status.idle":"2022-04-30T02:21:28.226741Z","shell.execute_reply.started":"2022-04-30T02:21:23.035512Z","shell.execute_reply":"2022-04-30T02:21:28.225768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> Data Visualisation","metadata":{}},{"cell_type":"code","source":"full_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T02:21:34.693766Z","iopub.execute_input":"2022-04-30T02:21:34.694506Z","iopub.status.idle":"2022-04-30T02:21:34.713998Z","shell.execute_reply.started":"2022-04-30T02:21:34.69446Z","shell.execute_reply":"2022-04-30T02:21:34.713226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data.describe()","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:07:34.292436Z","iopub.status.busy":"2022-04-18T00:07:34.2919Z","iopub.status.idle":"2022-04-18T00:07:34.370702Z","shell.execute_reply":"2022-04-18T00:07:34.369641Z","shell.execute_reply.started":"2022-04-18T00:07:34.292379Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups = full_data.groupby('label').count()\nlist_labels = [0 for i in range(5)]\nfor index, elt in groups.iterrows():\n    list_labels[index]=elt['text']","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:07:37.089289Z","iopub.status.busy":"2022-04-18T00:07:37.088197Z","iopub.status.idle":"2022-04-18T00:07:37.357511Z","shell.execute_reply":"2022-04-18T00:07:37.356482Z","shell.execute_reply.started":"2022-04-18T00:07:37.089226Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.bar([0,1,2,3,4],list_labels,align='center',width = 0.5)\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:07:38.656641Z","iopub.status.busy":"2022-04-18T00:07:38.65629Z","iopub.status.idle":"2022-04-18T00:07:38.881397Z","shell.execute_reply":"2022-04-18T00:07:38.88033Z","shell.execute_reply.started":"2022-04-18T00:07:38.656605Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### ","metadata":{}},{"cell_type":"markdown","source":"<h2> Preprocessing","metadata":{}},{"cell_type":"code","source":"X_stop_words = full_data.sample(n=10000)","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:07:44.884621Z","iopub.status.busy":"2022-04-18T00:07:44.883377Z","iopub.status.idle":"2022-04-18T00:07:45.093493Z","shell.execute_reply":"2022-04-18T00:07:45.092206Z","shell.execute_reply.started":"2022-04-18T00:07:44.884557Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_stop_words_pos = X_stop_words[X_stop_words['label']==4]\nX_stop_words_neg = X_stop_words[X_stop_words['label']==0]","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:07:51.448752Z","iopub.status.busy":"2022-04-18T00:07:51.44714Z","iopub.status.idle":"2022-04-18T00:07:51.457787Z","shell.execute_reply":"2022-04-18T00:07:51.456849Z","shell.execute_reply.started":"2022-04-18T00:07:51.448688Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_stop_words_pos.describe()","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:07:53.343928Z","iopub.status.busy":"2022-04-18T00:07:53.34279Z","iopub.status.idle":"2022-04-18T00:07:53.361984Z","shell.execute_reply":"2022-04-18T00:07:53.360703Z","shell.execute_reply.started":"2022-04-18T00:07:53.34387Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_stop_words_neg.describe()","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:07:55.652639Z","iopub.status.busy":"2022-04-18T00:07:55.651956Z","iopub.status.idle":"2022-04-18T00:07:55.671412Z","shell.execute_reply":"2022-04-18T00:07:55.670284Z","shell.execute_reply.started":"2022-04-18T00:07:55.652579Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"<h4> Nous allons créer un pipeline afin de mettre sous le bon format les tweets grâce à la bibliothèque Spacy : <br>\n     1. Passer toutes les lettres en lowercase <br>\n     2. Enlever la ponctuation<br>\n    3. Enlever les mots qui n'apporte rien à la sémentique du tweet <br>\n    4. Changer les mots par leur représentant de signification : 'running' -> 'run'\n ","metadata":{}},{"cell_type":"code","source":"!python3 -m spacy download en_core_web_sm","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:08:09.79009Z","iopub.status.busy":"2022-04-18T00:08:09.789763Z","iopub.status.idle":"2022-04-18T00:08:10.703249Z","shell.execute_reply":"2022-04-18T00:08:10.702113Z","shell.execute_reply.started":"2022-04-18T00:08:09.790057Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_tokens(text):\n    \"\"\"Extract tokens and metadata from individual spaCy doc.\"\"\"\n    doc = nlp(text)\n    tokens_return = []\n    for i in doc:\n        condition = not i.is_punct and not i.is_space and not i.is_stop\n        condition2 = not i.is_stop\n        #print(\"here we are looking at {} and the condition {} {}\".format(i,condition, condition2))\n        if condition:\n            #print(\"we are going from {} to {}\".format(j.text,j.lemma_))\n            #print(j.lemma_)\n            tokens_return.append(i.lemma_)\n    return ' '.join(tokens_return)","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:08:23.658276Z","iopub.status.busy":"2022-04-18T00:08:23.657962Z","iopub.status.idle":"2022-04-18T00:08:23.665646Z","shell.execute_reply":"2022-04-18T00:08:23.664632Z","shell.execute_reply.started":"2022-04-18T00:08:23.658244Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_tokens_plus_meta(doc):\n    \"\"\"Extract tokens and metadata from individual spaCy doc.\"\"\"\n    tokens_return = []\n    for j in doc:\n        for i in j:\n            condition = not i.is_punct and not i.is_space \n            condition2 = not i.is_stop\n            #print(\"here we are looking at {} and the condition {} {}\".format(i,condition, condition2))\n            if condition:\n                #print(\"we are going from {} to {}\".format(j.text,j.lemma_))\n                #print(j.lemma_)\n                tokens_return.append(i.lemma_)\n    return tokens_return","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:08:27.139969Z","iopub.status.busy":"2022-04-18T00:08:27.13897Z","iopub.status.idle":"2022-04-18T00:08:27.147458Z","shell.execute_reply":"2022-04-18T00:08:27.146248Z","shell.execute_reply.started":"2022-04-18T00:08:27.139922Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc_pos = nlp.pipe(X_stop_words_pos.text)\ndoc_neg = nlp.pipe(X_stop_words_neg.text)","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:08:29.276736Z","iopub.status.busy":"2022-04-18T00:08:29.276455Z","iopub.status.idle":"2022-04-18T00:08:29.282504Z","shell.execute_reply":"2022-04-18T00:08:29.281366Z","shell.execute_reply.started":"2022-04-18T00:08:29.276706Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_tokens_pos = []\nlist_mots = []\nnb_pos_dict = {}\ntweets_pos=extract_tokens_plus_meta(doc_pos)\n#tweets_neg= extract_tokens_plus_meta(doc_neg) \nfor mot in tweets_pos:\n    if(mot not in list_mots):\n        list_mots.append(mot)\n        count = tweets_pos.count(mot)\n        nb_pos_dict[mot] = count\n        nb_tokens_pos.append([mot,count])\n    ","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:08:31.320292Z","iopub.status.busy":"2022-04-18T00:08:31.319931Z","iopub.status.idle":"2022-04-18T00:09:00.507853Z","shell.execute_reply":"2022-04-18T00:09:00.50661Z","shell.execute_reply.started":"2022-04-18T00:08:31.320255Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_tokens_neg = []\ntweets_neg=extract_tokens_plus_meta(doc_neg)\n#tweets_neg= extract_tokens_plus_meta(doc_neg) \nlist_mots2 = []\nnb_neg_dict = {}\nfor mot in tweets_neg:\n    if(mot not in list_mots2):\n        count = tweets_neg.count(mot)\n        list_mots2.append(mot)\n        nb_neg_dict[mot] = count\n        nb_tokens_neg.append([mot,count])","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:09:00.509966Z","iopub.status.busy":"2022-04-18T00:09:00.50973Z","iopub.status.idle":"2022-04-18T00:09:28.742149Z","shell.execute_reply":"2022-04-18T00:09:28.741073Z","shell.execute_reply.started":"2022-04-18T00:09:00.509938Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#nb_neg_dict['not']","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:09:51.297776Z","iopub.status.busy":"2022-04-18T00:09:51.297432Z","iopub.status.idle":"2022-04-18T00:09:51.305884Z","shell.execute_reply":"2022-04-18T00:09:51.304995Z","shell.execute_reply.started":"2022-04-18T00:09:51.297742Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_tokens_pos.sort(key=lambda x: x[1], reverse=True)\nnb_tokens_neg.sort(key=lambda x: x[1], reverse=True)\nword_tokens_pos = [x[0] for x in nb_tokens_pos[:500]]\nword_tokens_neg = [x[0] for x in nb_tokens_neg[:500]]","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:09:54.338542Z","iopub.status.busy":"2022-04-18T00:09:54.338227Z","iopub.status.idle":"2022-04-18T00:09:54.351198Z","shell.execute_reply":"2022-04-18T00:09:54.349702Z","shell.execute_reply.started":"2022-04-18T00:09:54.338506Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def condition(mot,seuille):\n    if(not mot in list_mots2):\n        return True\n    if(not mot in list_mots):\n        return True\n    if(nb_neg_dict[mot]/nb_pos_dict[mot]>seuille or nb_pos_dict[mot]/nb_neg_dict[mot]> seuille):\n        return True","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:09:56.136876Z","iopub.status.busy":"2022-04-18T00:09:56.136547Z","iopub.status.idle":"2022-04-18T00:09:56.142817Z","shell.execute_reply":"2022-04-18T00:09:56.142014Z","shell.execute_reply.started":"2022-04-18T00:09:56.13684Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_stop_words = []\ndef creation_stop_words(pos, neg,seuille1,seuille2):\n    for mot in word_tokens_pos[:seuille1]:\n        if condition(mot,seuille2):\n            not_stop_words.append(mot)\n    for mot in word_tokens_neg[:seuille1]:\n        if condition(mot,seuille2):\n            not_stop_words.append(mot)\n    ","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:09:58.056881Z","iopub.status.busy":"2022-04-18T00:09:58.056558Z","iopub.status.idle":"2022-04-18T00:09:58.063643Z","shell.execute_reply":"2022-04-18T00:09:58.062517Z","shell.execute_reply.started":"2022-04-18T00:09:58.056848Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"creation_stop_words(word_tokens_pos,word_tokens_neg,300,2)","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:10:02.72638Z","iopub.status.busy":"2022-04-18T00:10:02.72604Z","iopub.status.idle":"2022-04-18T00:10:02.744007Z","shell.execute_reply":"2022-04-18T00:10:02.743094Z","shell.execute_reply.started":"2022-04-18T00:10:02.726349Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for word in not_stop_words:\n    nlp.vocab[word].is_stop=False\n    try:\n        #print(word)\n        nlp.Defaults.stop_words.remove(word)\n    except:\n        print(word + ' is not in stop words')","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:10:05.690792Z","iopub.status.busy":"2022-04-18T00:10:05.690507Z","iopub.status.idle":"2022-04-18T00:10:05.711854Z","shell.execute_reply":"2022-04-18T00:10:05.710833Z","shell.execute_reply.started":"2022-04-18T00:10:05.690759Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp.vocab['not'].is_stop","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:10:10.858601Z","iopub.status.busy":"2022-04-18T00:10:10.858246Z","iopub.status.idle":"2022-04-18T00:10:10.865506Z","shell.execute_reply":"2022-04-18T00:10:10.864603Z","shell.execute_reply.started":"2022-04-18T00:10:10.858565Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectKBest, chi2\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-04-30T02:24:21.555485Z","iopub.execute_input":"2022-04-30T02:24:21.55639Z","iopub.status.idle":"2022-04-30T02:24:21.561655Z","shell.execute_reply.started":"2022-04-30T02:24:21.556349Z","shell.execute_reply":"2022-04-30T02:24:21.560678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We clean the Dataset\n#full_data['cleaned_text'] = full_data['text'].apply(extract_tokens)\n","metadata":{"execution":{"iopub.execute_input":"2022-04-18T00:10:37.238207Z","iopub.status.busy":"2022-04-18T00:10:37.237913Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We save the datasets that are cleaned\n#full_data.to_csv('./full_data_cleaned.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mapping_labels(number):\n    if(number==0):\n        return 0\n    else:\n        return 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfull_data = pd.read_csv('../input/data-groups/full_data_cleaned2.csv')\nfull_data = full_data.dropna()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:10:43.281518Z","iopub.status.idle":"2022-04-30T21:10:43.282019Z","shell.execute_reply.started":"2022-04-30T21:10:43.281769Z","shell.execute_reply":"2022-04-30T21:10:43.281797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creation d'un Dataset à 5 catégories","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nnltk.downloader.download('vader_lexicon')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sen = SentimentIntensityAnalyzer()\nsen.polarity_scores(test_text)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_groups(dict_positivity):\n    if(dict_positivity['neg']>0.7):\n        return -2\n    elif(dict_positivity['pos']>0.7):\n        return 2\n    elif(dict_positivity['neu']>.7):\n        return 0\n    elif(dict_positivity['pos']>dict_positivity['neu']+dict_positivity['neg']):\n        return 1\n    elif(dict_positivity['neg']>dict_positivity['neg']+dict_positivity['pos']):\n        return -1\n    else:\n        return 0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mapping_text_to_group(text):\n    score = sen.polarity_scores(text)\n    return map_groups(score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data['group5'] = full_data['cleaned_text'].apply(mapping_text_to_group)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> TF-IDF model","metadata":{}},{"cell_type":"code","source":"full_data = pd.read_csv('../input/data-groups/full_data_cleaned2.csv')\nX_train, X_val, y_train, y_val = train_test_split(full_data['cleaned_text'].values, full_data.label, test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:10:43.283473Z","iopub.status.idle":"2022-04-30T21:10:43.284045Z","shell.execute_reply.started":"2022-04-30T21:10:43.283773Z","shell.execute_reply":"2022-04-30T21:10:43.283802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"financial_data = pd.read_csv('../input/data-groups/financial_data_2_cleaned.csv')\nX_train_finance, X_val_finance, y_train_finance, y_val_finance = train_test_split(financial_data['cleaned_text'].values, financial_data.target, test_size=0.25)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_group_3 = pd.read_csv('../input/data-groups/eurecom_data.csv').dropna()\nX_train3, X_val3, y_train3, y_val3 = train_test_split(data_group_3['cleaned_text'].values, data_group_3.target, test_size=0.25)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n                      ('chi',  SelectKBest(chi2, k=10000)),\n                     ('clf', LinearSVC(C=1.0, penalty='l2', max_iter=20000, dual=False))])\nmodel = pipeline.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline2 = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n                      ('chi',  SelectKBest(chi2, k=10000)),\n                     ('clf', LinearSVC(C=1.0, penalty='l2', max_iter=20000, dual=False))])\nmodel2 = pipeline2.fit(X_train3, y_train3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline3 = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n                      ('chi',  SelectKBest(chi2, k=10000)),\n                     ('clf', LinearSVC(C=1.0, penalty='l2', max_iter=20000, dual=False))])\nmodel3 = pipeline3.fit(X_train_finance, y_train_finance)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results TFIDF","metadata":{}},{"cell_type":"code","source":"vectorizer = model2.named_steps['vect']\nchi = model2.named_steps['chi']\nclf = model2.named_steps['clf']\n\nfeature_names = vectorizer.get_feature_names()\nfeature_names = [feature_names[i] for i in chi.get_support(indices=True)]\nfeature_names = np.asarray(feature_names)\n\ntarget_names = ['-1', '0', '1']\nprint(\"top 10 keywords per class:\")\nimportant_words = {}\nfor i, label in enumerate(target_names):\n    top = np.argsort(clf2.coef_[i])[-30:]\n    important_words[i] = \" \".join(feature_names[top])\n    print(\"%s: %s\" % (label, \" \".join(feature_names[top])))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:10:43.28527Z","iopub.status.idle":"2022-04-30T21:10:43.285576Z","shell.execute_reply.started":"2022-04-30T21:10:43.285419Z","shell.execute_reply":"2022-04-30T21:10:43.285435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud = WordCloud(width = 800, height = 800,\n                background_color ='white',\n                min_font_size = 10).generate(important_words[0])\n \n# plot the WordCloud image                      \nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n \nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score\nprint(\"Accuracy score SVC: \" + str(model.score(X_val, y_val)))\nval_predict = model.predict(X_val)\ny_val_array =np.array(y_val)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx = confusion_matrix(y_val_array,val_predict)\nax = plt.axes()\nsn.heatmap(confusion_mtx, annot=True,annot_kws={\"size\": 15}, cmap=\"Reds\", ax = ax,xticklabels=[-1,0,1],yticklabels=[-1,0,1])\n#ax.set_title('Validation Accuracy first Try', size=14)\nplt.show()\nprint(val_predict-y_val_array)\nprint(\"Distance between our target and prediction: \" + str(np.linalg.norm(val_predict-y_val_array)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score\nprint(\"Accuracy score SVC: \" + str(model2.score(X_train3, y_train3)))\nval_predict3 = model2.predict(X_val3)\ny_val_array3 =np.array(y_train_finance)\nprint('F1 score with SVC : ' + str(fbeta_score(y_val_array3,val_predict3,1,average='macro')))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx = confusion_matrix(y_val_array3,val_predict3)\nax = plt.axes()\nsn.heatmap(confusion_mtx, annot=True,annot_kws={\"size\": 15}, cmap=\"Reds\", ax = ax,xticklabels=[-1,0,1],yticklabels=[-1,0,1])\n#ax.set_title('Validation Accuracy first Try', size=14)\nplt.show()\nprint(val_predict-y_val_array)\nprint(\"Distance between our target and prediction: \" + str(np.linalg.norm(val_predict-y_val_array)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score\nprint(\"Accuracy score SVC: \" + str(model3.score(X_val_finance, y_val_finance)))\nval_predict3 = model3.predict(X_val_finance)\ny_val_array3 =np.array(y_val_finance)\nprint('F1 score with SVC : ' + str(fbeta_score(y_val_array3,val_predict3,1,average='macro')))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx = confusion_matrix(y_val_array3,val_predict3)\nax = plt.axes()\nsn.heatmap(confusion_mtx, annot=True,annot_kws={\"size\": 15}, cmap=\"Reds\", ax = ax,xticklabels=[-1,0,1],yticklabels=[-1,0,1])\n#ax.set_title('Validation Accuracy first Try', size=14)\nplt.show()\nprint(val_predict-y_val_array)\nprint(\"Distance between our target and prediction: \" + str(np.linalg.norm(val_predict-y_val_array)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BERT","metadata":{}},{"cell_type":"code","source":"! pip install transformers==3","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:18:55.163245Z","iopub.execute_input":"2022-04-30T21:18:55.163503Z","iopub.status.idle":"2022-04-30T21:19:08.33307Z","shell.execute_reply.started":"2022-04-30T21:18:55.163474Z","shell.execute_reply":"2022-04-30T21:19:08.332134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\nfrom transformers import InputExample, InputFeatures\n\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom collections import defaultdict\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:19:08.336839Z","iopub.execute_input":"2022-04-30T21:19:08.337106Z","iopub.status.idle":"2022-04-30T21:19:10.108807Z","shell.execute_reply.started":"2022-04-30T21:19:08.337076Z","shell.execute_reply":"2022-04-30T21:19:10.107985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfull_data = pd.read_csv('../input/data-groups/full_data_cleaned2.csv')\nfull_data = full_data.dropna()\nfull_data = full_data.sample(10000)\nfrom sklearn.model_selection import train_test_split\nData_train, Data_val = train_test_split(full_data, test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:25:06.201731Z","iopub.execute_input":"2022-04-30T21:25:06.202263Z","iopub.status.idle":"2022-04-30T21:25:12.923132Z","shell.execute_reply.started":"2022-04-30T21:25:06.202223Z","shell.execute_reply":"2022-04-30T21:25:12.922366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping_conversion={4:1,0:0}\nData_val['target']=Data_val['label'].map(mapping_conversion)\nData_train['target']=Data_train['label'].map(mapping_conversion)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:25:14.879598Z","iopub.execute_input":"2022-04-30T21:25:14.88009Z","iopub.status.idle":"2022-04-30T21:25:14.889274Z","shell.execute_reply.started":"2022-04-30T21:25:14.880053Z","shell.execute_reply":"2022-04-30T21:25:14.887247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\ntokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:19:18.31199Z","iopub.execute_input":"2022-04-30T21:19:18.312406Z","iopub.status.idle":"2022-04-30T21:19:19.332378Z","shell.execute_reply.started":"2022-04-30T21:19:18.312357Z","shell.execute_reply":"2022-04-30T21:19:19.331672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T04:27:34.452454Z","iopub.execute_input":"2022-04-30T04:27:34.453214Z","iopub.status.idle":"2022-04-30T04:27:34.459481Z","shell.execute_reply.started":"2022-04-30T04:27:34.453164Z","shell.execute_reply":"2022-04-30T04:27:34.458903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:19:23.238524Z","iopub.execute_input":"2022-04-30T21:19:23.239094Z","iopub.status.idle":"2022-04-30T21:19:23.243089Z","shell.execute_reply.started":"2022-04-30T21:19:23.239053Z","shell.execute_reply":"2022-04-30T21:19:23.242233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data_train","metadata":{"execution":{"iopub.status.busy":"2022-04-30T05:30:07.480168Z","iopub.execute_input":"2022-04-30T05:30:07.480494Z","iopub.status.idle":"2022-04-30T05:30:07.50044Z","shell.execute_reply.started":"2022-04-30T05:30:07.480456Z","shell.execute_reply":"2022-04-30T05:30:07.499503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token_lens = []\nfor txt in Data_train.cleaned_text :\n  tokens = tokenizer.encode(txt, max_length=512)\n  token_lens.append(len(tokens))\n    \n\nplt.figure(figsize=(16,8))    \nsns.distplot(token_lens)\nMax_len = max(token_lens)\nplt.xlim([0, 256]);\nplt.xlabel('Token count');\nprint(\"Max token_lens : \", max(token_lens))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:25:20.37798Z","iopub.execute_input":"2022-04-30T21:25:20.378236Z","iopub.status.idle":"2022-04-30T21:25:22.767282Z","shell.execute_reply.started":"2022-04-30T21:25:20.378208Z","shell.execute_reply":"2022-04-30T21:25:22.766503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SentimentClassifier(nn.Module):\n    \n  def __init__(self, n_classes):\n    super(SentimentClassifier, self).__init__()\n    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n    self.drop = nn.Dropout(p=0.3)\n    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n    \n  def forward(self, input_ids, attention_mask):\n    _, pooled_output = self.bert(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n    output = self.drop(pooled_output)\n    return self.out(output)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:25:25.941258Z","iopub.execute_input":"2022-04-30T21:25:25.94212Z","iopub.status.idle":"2022-04-30T21:25:25.949099Z","shell.execute_reply.started":"2022-04-30T21:25:25.942072Z","shell.execute_reply":"2022-04-30T21:25:25.948003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SentimentClassifier(2)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:25:58.100978Z","iopub.execute_input":"2022-04-30T21:25:58.101229Z","iopub.status.idle":"2022-04-30T21:26:01.621234Z","shell.execute_reply.started":"2022-04-30T21:25:58.101202Z","shell.execute_reply":"2022-04-30T21:26:01.620529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GPReviewDataset(Dataset):\n  def __init__(self, reviews, targets, tokenizer, max_len):\n    self.reviews = reviews\n    self.targets = targets\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n  def __len__(self):\n    return len(self.reviews)\n  def __getitem__(self, item):\n    review = str(self.reviews[item])\n    target = self.targets[item]\n    encoding = self.tokenizer.encode_plus(\n      review,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      return_token_type_ids=False,\n      pad_to_max_length=True,\n      return_attention_mask=True,\n      return_tensors='pt',\n    )\n    return {\n      'review_text': review,\n      'input_ids': encoding['input_ids'].flatten(),\n      'attention_mask': encoding['attention_mask'].flatten(),\n      'targets': torch.tensor(target, dtype=torch.long)\n    }","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:26:03.278299Z","iopub.execute_input":"2022-04-30T21:26:03.278954Z","iopub.status.idle":"2022-04-30T21:26:03.288485Z","shell.execute_reply.started":"2022-04-30T21:26:03.278916Z","shell.execute_reply":"2022-04-30T21:26:03.287622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2022-04-30T05:06:45.188403Z","iopub.execute_input":"2022-04-30T05:06:45.189307Z","iopub.status.idle":"2022-04-30T05:06:45.195931Z","shell.execute_reply.started":"2022-04-30T05:06:45.189247Z","shell.execute_reply":"2022-04-30T05:06:45.195241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_data_loader(df, tokenizer, max_len, batch_size):\n  ds = GPReviewDataset(\n    reviews=df.cleaned_text.to_numpy(),\n    targets=df.target.to_numpy(),\n    tokenizer=tokenizer,\n    max_len=max_len\n  )\n  return DataLoader(\n    ds,\n    batch_size=batch_size,\n    num_workers=4\n  )\nBATCH_SIZE = 16\ntrain_data_loader = create_data_loader(Data_train, tokenizer, Max_len, BATCH_SIZE)\nval_data_loader = create_data_loader(Data_val, tokenizer, Max_len, BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:26:06.51678Z","iopub.execute_input":"2022-04-30T21:26:06.517026Z","iopub.status.idle":"2022-04-30T21:26:06.525669Z","shell.execute_reply.started":"2022-04-30T21:26:06.516999Z","shell.execute_reply":"2022-04-30T21:26:06.52482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 3\noptimizer = AdamW(model.parameters(), lr=3e-5, correct_bias=False)\ntotal_steps = len(train_data_loader) * EPOCHS\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\nloss_fn = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:26:19.258514Z","iopub.execute_input":"2022-04-30T21:26:19.259225Z","iopub.status.idle":"2022-04-30T21:26:19.265633Z","shell.execute_reply.started":"2022-04-30T21:26:19.259181Z","shell.execute_reply":"2022-04-30T21:26:19.264931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:26:23.455849Z","iopub.execute_input":"2022-04-30T21:26:23.456123Z","iopub.status.idle":"2022-04-30T21:26:26.203468Z","shell.execute_reply.started":"2022-04-30T21:26:23.456092Z","shell.execute_reply":"2022-04-30T21:26:26.202712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(\n  model,\n  data_loader,\n  loss_fn,\n  optimizer,\n    device,\n  scheduler,\n  n_examples\n):\n  model = model.train()\n  losses = []\n  correct_predictions = 0\n  for d in data_loader:\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"targets\"].to(device)\n    outputs = model(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n    _, preds = torch.max(outputs, dim=1)\n    loss = loss_fn(outputs, targets)\n    correct_predictions += torch.sum(preds == targets)\n    losses.append(loss.item())\n    loss.backward()\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    optimizer.step()\n    scheduler.step()\n    optimizer.zero_grad()\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:26:29.150177Z","iopub.execute_input":"2022-04-30T21:26:29.150437Z","iopub.status.idle":"2022-04-30T21:26:29.160978Z","shell.execute_reply.started":"2022-04-30T21:26:29.15041Z","shell.execute_reply":"2022-04-30T21:26:29.160209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, data_loader, loss_fn, device, n_examples):\n  model = model.eval()\n  losses = []\n  correct_predictions = 0\n  with torch.no_grad():\n    for d in data_loader:\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n      _, preds = torch.max(outputs, dim=1)\n      loss = loss_fn(outputs, targets)\n      correct_predictions += torch.sum(preds == targets)\n      losses.append(loss.item())\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:26:33.215353Z","iopub.execute_input":"2022-04-30T21:26:33.215611Z","iopub.status.idle":"2022-04-30T21:26:33.222716Z","shell.execute_reply.started":"2022-04-30T21:26:33.215582Z","shell.execute_reply":"2022-04-30T21:26:33.221998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"istory = defaultdict(list)\nbest_accuracy = 0\nfor epoch in range(EPOCHS):\n  print(f'Epoch {epoch + 1}/{EPOCHS}')\n  print('-' * 10)\n  train_acc, train_loss = train_epoch(\n    model,\n    train_data_loader,\n    loss_fn,\n    optimizer,\n    device,\n    scheduler,\n    len(Data_train)\n  )\n  print(f'Train loss {train_loss} accuracy {train_acc}')\n  val_acc, val_loss = eval_model(\n    model,\n    val_data_loader,\n    loss_fn,\n    device,\n    len(Data_val)\n  )\n  print(f'Val   loss {val_loss} accuracy {val_acc}')\n  print()\n  history['train_acc'].append(train_acc)\n  history['train_loss'].append(train_loss)\n  history['val_acc'].append(val_acc)\n  history['val_loss'].append(val_loss)\n  if val_acc > best_accuracy:\n    torch.save(model.state_dict(), 'best_model_state.bin')\n    best_accuracy = val_acc","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:26:36.75115Z","iopub.execute_input":"2022-04-30T21:26:36.751715Z","iopub.status.idle":"2022-04-30T21:26:37.66628Z","shell.execute_reply.started":"2022-04-30T21:26:36.751668Z","shell.execute_reply":"2022-04-30T21:26:37.664177Z"},"trusted":true},"execution_count":null,"outputs":[]}]}